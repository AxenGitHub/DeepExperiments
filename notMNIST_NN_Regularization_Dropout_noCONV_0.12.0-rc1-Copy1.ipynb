{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Connected Naural Networks - Regularization/Dropout - No Convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First reload the data we generated in __notMNIST_nonTensorFlow_comparisons.ipynb__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "\n",
    "* data as a flat matrix,\n",
    "* labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 1 to [0.0, 1.0, 0.0 ...], 2 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "Let's introduce Dropout on the hidden layers of the neural networks. \n",
    "Remember: __Dropout should only be introduced during training, not evaluation__, otherwise your evaluation results would be stochastic as well. \n",
    "__TensorFlow provides nn.dropout() for that, but we have to make sure it's only inserted during training__.\n",
    "\n",
    "### `tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None, name=None)` {#dropout}\n",
    "\n",
    "Computes dropout.\n",
    "\n",
    "With probability `keep_prob`, outputs the input element scaled up by\n",
    "`1 / keep_prob`, otherwise outputs `0`.  The scaling is so that the expected\n",
    "sum is unchanged.\n",
    "\n",
    "By default, each element is kept or dropped independently.  If `noise_shape`\n",
    "is specified, it must be\n",
    "[broadcastable](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
    "to the shape of `x`, and only dimensions with `noise_shape[i] == shape(x)[i]`\n",
    "will make independent decisions.  For example, if `shape(x) = [k, l, m, n]`\n",
    "and `noise_shape = [k, 1, 1, n]`, each batch and channel component will be\n",
    "kept independently and each row and column will be kept or not kept together.\n",
    "\n",
    "##### Args:\n",
    "\n",
    "\n",
    "*  <b>`x`</b>: A tensor.\n",
    "*  <b>`keep_prob`</b>: A scalar `Tensor` with the same type as x. The probability\n",
    "    that each element is kept.\n",
    "*  <b>`noise_shape`</b>: A 1-D `Tensor` of type `int32`, representing the\n",
    "    shape for randomly generated keep/drop flags.\n",
    "*  <b>`seed`</b>: A Python integer. Used to create random seeds. See\n",
    "    [`set_random_seed`](../../api_docs/python/constant_op.md#set_random_seed)\n",
    "    for behavior.\n",
    "*  <b>`name`</b>: A name for this operation (optional).\n",
    "\n",
    "##### Returns:\n",
    "\n",
    "  A Tensor of the same shape of `x`.\n",
    "\n",
    "##### Raises:\n",
    "\n",
    "\n",
    "*  <b>`ValueError`</b>: If `keep_prob` is not in `(0, 1]`.\n",
    "                                                   \n",
    "### HowTo\n",
    "We create a placeholder for the probability that a neuron's output is kept during dropout. \n",
    "This allows us to turn dropout on during training, and turn it off during testing. \n",
    "TensorFlow's tf.nn.dropout op automatically handles scaling neuron outputs in addition to masking them, so dropout just works without any additional scaling\n",
    "\n",
    "Further details: https://www.tensorflow.org/versions/r0.11/tutorials/mnist/pros/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks models: 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def create_nn1_model_dropout_and_run(graph,\n",
    "                         train_dataset,\n",
    "                         train_labels,\n",
    "                         valid_dataset,\n",
    "                         valid_labels,\n",
    "                         test_dataset,\n",
    "                         test_labels,\n",
    "                         dropout,\n",
    "                         num_steps,\n",
    "                         hidden_size = 1024, \n",
    "                         num_labels=10,batch_size = 128):\n",
    "    \n",
    "    uniMax = 1/math.sqrt(hidden_size)\n",
    "    \n",
    "    with graph.as_default():\n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        \n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "      # Hidden 1\n",
    "      weights_1 = tf.Variable(tf.random_uniform([image_size * image_size, hidden_size], minval=-uniMax, maxval=uniMax),\n",
    "                             name='weights_1')\n",
    "      biases_1 = tf.Variable(tf.random_uniform([hidden_size],minval=-uniMax, maxval=uniMax),name='biases_1')\n",
    "      hidden_1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "      \n",
    "      if dropout>0: \n",
    "        dropped = tf.nn.dropout(hidden_1, dropout)\n",
    "      else:\n",
    "        dropped = hidden_1\n",
    "\n",
    "      # Softmax \n",
    "      weights_2 = tf.Variable(tf.random_uniform([hidden_size, num_labels],minval=-uniMax, maxval=uniMax), name='weights_2')\n",
    "      biases_2 = tf.Variable(tf.random_uniform([num_labels],minval=-uniMax, maxval=uniMax),name='biases_2')\n",
    "      logits = tf.matmul(dropped, weights_2) + biases_2\n",
    "\n",
    "      # \n",
    "      loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "      # Optimizer.\n",
    "      global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "      learning_rate = tf.train.exponential_decay(0.5, global_step, 100000, 0.96, staircase=True)\n",
    "      optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "      #optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "\n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "      valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1), weights_2) + biases_2)\n",
    "      test_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1), weights_2) + biases_2)\n",
    "\n",
    "    test_accuracy = 0\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            \n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "           \n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            \n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "              valid_prediction.eval(), valid_labels))\n",
    "              test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "              print(\"Test accuracy: %.1f%%\" % test_accuracy)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>> keep_prob: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.315333\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 34.9%\n",
      "Test accuracy: 37.2%\n",
      "Minibatch loss at step 500: 0.357309\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 91.8%\n",
      "Minibatch loss at step 1000: 0.540357\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.7%\n",
      "Minibatch loss at step 1500: 0.293043\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 2000: 0.282493\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 2500: 0.339409\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 3000: 0.354558\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.3%\n",
      "\n",
      ">>>>>>>>>> keep_prob: 0.300000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.343650\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 37.4%\n",
      "Test accuracy: 40.7%\n",
      "Minibatch loss at step 500: 0.604629\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.1%\n",
      "Test accuracy: 90.9%\n",
      "Minibatch loss at step 1000: 0.666325\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.5%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1500: 0.573536\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 2000: 0.414929\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 2500: 0.579069\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 3000: 0.544650\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.2%\n",
      "Test accuracy: 92.9%\n",
      "\n",
      ">>>>>>>>>> keep_prob: 0.400000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307111\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 33.8%\n",
      "Test accuracy: 36.1%\n",
      "Minibatch loss at step 500: 0.491085\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.5%\n",
      "Test accuracy: 91.1%\n",
      "Minibatch loss at step 1000: 0.625153\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.9%\n",
      "Minibatch loss at step 1500: 0.437642\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 2000: 0.382675\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 2500: 0.475697\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.7%\n",
      "Test accuracy: 93.1%\n",
      "Minibatch loss at step 3000: 0.499541\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 93.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.306122\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 31.4%\n",
      "Test accuracy: 33.8%\n",
      "Minibatch loss at step 500: 0.426311\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 84.6%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.588321\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1500: 0.344181\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.9%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 2000: 0.301023\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.7%\n",
      "Test accuracy: 93.4%\n",
      "Minibatch loss at step 2500: 0.438312\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 3000: 0.448816\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.4%\n",
      "\n",
      ">>>>>>>>>> keep_prob: 0.600000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.297631\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 42.3%\n",
      "Test accuracy: 46.2%\n",
      "Minibatch loss at step 500: 0.388815\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.9%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1000: 0.584715\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 1500: 0.376472\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2000: 0.322120\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.4%\n",
      "Minibatch loss at step 2500: 0.362604\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 3000: 0.450495\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.9%\n",
      "\n",
      ">>>>>>>>>> keep_prob: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307561\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 35.5%\n",
      "Test accuracy: 38.6%\n",
      "Minibatch loss at step 500: 0.406717\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.576053\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 1500: 0.302879\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2000: 0.295290\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.3%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2500: 0.381301\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 3000: 0.405640\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "keep_probs = [0, 0.3,0.4, 0.5, 0.6,0.7]\n",
    "test_accuracy = np.zeros(len(keep_probs))\n",
    "i = 0\n",
    "for keep_prob in keep_probs:\n",
    "  print(\"\\n>>>>>>>>>> keep_prob: %f\" % keep_prob)\n",
    "  graph = tf.Graph()\n",
    "  test_accuracy[i] = create_nn1_model_dropout_and_run(graph,\n",
    "                         train_dataset,\n",
    "                         train_labels,\n",
    "                         valid_dataset,\n",
    "                         valid_labels,\n",
    "                         test_dataset,\n",
    "                         test_labels,\n",
    "                         keep_prob,\n",
    "                         num_steps)\n",
    "   \n",
    "  i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Best keep_prob:0 -- accuracy:94.26\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Best keep_prob:\"+str(keep_probs[np.argmax(test_accuracy)])+ \" -- accuracy:\" + str(test_accuracy[np.argmax(test_accuracy)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We did not get an improvement in test accuracy__ by using dropout as the best accuracy occours for \n",
    "keep_prob=0 that means no dropout.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks models: 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_nn2_model_dropout_and_run(graph,\n",
    "                         train_dataset,\n",
    "                         train_labels,\n",
    "                         valid_dataset,\n",
    "                         valid_labels,\n",
    "                         test_dataset,\n",
    "                         test_labels,\n",
    "                         dropout_vect,\n",
    "                         num_steps,\n",
    "                         hidden_size = 1024, \n",
    "                         num_labels=10,batch_size = 128):\n",
    "    \n",
    "    assert dropout_vect.shape == (2,)\n",
    "    \n",
    "    uniMax = 1/math.sqrt(hidden_size)\n",
    "    \n",
    "    with graph.as_default():\n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        \n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "      # Hidden 1\n",
    "      weights_1 = tf.Variable(tf.random_uniform([image_size * image_size, hidden_size], minval=-uniMax, maxval=uniMax),\n",
    "                             name='weights_1')\n",
    "      biases_1 = tf.Variable(tf.random_uniform([hidden_size],minval=-uniMax, maxval=uniMax),name='biases_1')\n",
    "      hidden_1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "      \n",
    "      if dropout_vect[0]>0: \n",
    "        dropped_1 = tf.nn.dropout(hidden_1, dropout_vect[0])\n",
    "      else:\n",
    "        dropped_1 = hidden_1\n",
    "    \n",
    "      # Hidden 2\n",
    "      weights_2 = tf.Variable(tf.random_uniform([hidden_size, hidden_size], minval=-uniMax, maxval=uniMax),name='weights_2')\n",
    "      biases_2 = tf.Variable(tf.random_uniform([hidden_size],minval=-uniMax, maxval=uniMax),name='biases_2')\n",
    "      hidden_2 = tf.nn.relu(tf.matmul(dropped_1, weights_2) + biases_2)\n",
    "    \n",
    "      if dropout_vect[1]>0: \n",
    "        dropped_2 = tf.nn.dropout(hidden_2, dropout_vect[1])\n",
    "      else:\n",
    "        dropped_2 = hidden_2\n",
    "        \n",
    "      # Softmax \n",
    "      weights_3 = tf.Variable(tf.random_uniform([hidden_size, num_labels],minval=-uniMax, maxval=uniMax), name='weights_3')\n",
    "      biases_3 = tf.Variable(tf.random_uniform([num_labels],minval=-uniMax, maxval=uniMax),name='biases_3')\n",
    "      logits = tf.matmul(dropped_2, weights_3) + biases_3\n",
    "\n",
    "      # \n",
    "      loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "      # Optimizer.\n",
    "      global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "      learning_rate = tf.train.exponential_decay(0.5, global_step, 100000, 0.96, staircase=True)\n",
    "      optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "      #optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "\n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "      valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1), weights_2) + biases_2),\n",
    "                  weights_3) + biases_3)\n",
    "      test_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1), weights_2) + biases_2), \n",
    "                   weights_3) + biases_3)\n",
    "\n",
    "    test_accuracy = 0\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            \n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "           \n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            \n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "              valid_prediction.eval(), valid_labels))\n",
    "              test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "              print(\"Test accuracy: %.1f%%\" % test_accuracy)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.312819\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 31.7%\n",
      "Test accuracy: 34.7%\n",
      "Minibatch loss at step 500: 0.345798\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1000: 0.479616\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.7%\n",
      "Test accuracy: 93.1%\n",
      "Minibatch loss at step 1500: 0.254761\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2000: 0.240032\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 2500: 0.304383\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.0%\n",
      "Test accuracy: 95.0%\n",
      "Minibatch loss at step 3000: 0.336706\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.1%\n",
      "Test accuracy: 94.9%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.300000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302322\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 29.5%\n",
      "Test accuracy: 31.3%\n",
      "Minibatch loss at step 500: 0.378720\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.516540\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 93.0%\n",
      "Minibatch loss at step 1500: 0.304261\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.286544\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.359491\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 3000: 0.367913\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.5%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.400000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.304077\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 27.0%\n",
      "Test accuracy: 29.7%\n",
      "Minibatch loss at step 500: 0.358256\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.519137\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 1500: 0.296490\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2000: 0.279853\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.342422\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 3000: 0.390573\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.4%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.301950\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 26.3%\n",
      "Test accuracy: 28.6%\n",
      "Minibatch loss at step 500: 0.366997\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.4%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.503119\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 1500: 0.250260\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 2000: 0.285485\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 2500: 0.291745\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.8%\n",
      "Minibatch loss at step 3000: 0.337206\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.0%\n",
      "Test accuracy: 94.9%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.600000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.318914\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 23.8%\n",
      "Test accuracy: 25.1%\n",
      "Minibatch loss at step 500: 0.367812\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.1%\n",
      "Minibatch loss at step 1000: 0.447942\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.7%\n",
      "Minibatch loss at step 1500: 0.279314\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2000: 0.279991\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 2500: 0.317560\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.5%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 3000: 0.333775\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.6%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.306290\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 22.5%\n",
      "Test accuracy: 23.8%\n",
      "Minibatch loss at step 500: 0.362070\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.471089\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 93.0%\n",
      "Minibatch loss at step 1500: 0.245662\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 2000: 0.264737\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.337165\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.8%\n",
      "Test accuracy: 94.9%\n",
      "Minibatch loss at step 3000: 0.360916\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.9%\n",
      "Test accuracy: 94.8%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.300000 ---- keep_prob_2: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307198\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 23.6%\n",
      "Test accuracy: 25.4%\n",
      "Minibatch loss at step 500: 0.384082\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.4%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1000: 0.487637\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1500: 0.390197\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 2000: 0.358455\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 2500: 0.422655\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 3000: 0.428847\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.5%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.300000 ---- keep_prob_2: 0.300000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.311280\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 26.9%\n",
      "Test accuracy: 29.2%\n",
      "Minibatch loss at step 500: 0.535063\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.9%\n",
      "Test accuracy: 91.0%\n",
      "Minibatch loss at step 1000: 0.549111\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.4%\n",
      "Test accuracy: 91.1%\n",
      "Minibatch loss at step 1500: 0.491555\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.7%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 2000: 0.489481\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 2500: 0.570864\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 84.8%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 3000: 0.573710\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 84.4%\n",
      "Test accuracy: 91.3%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.300000 ---- keep_prob_2: 0.400000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.304840\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 23.2%\n",
      "Test accuracy: 24.9%\n",
      "Minibatch loss at step 500: 0.543830\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.2%\n",
      "Test accuracy: 90.9%\n",
      "Minibatch loss at step 1000: 0.575046\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 84.4%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1500: 0.327899\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 2000: 0.366576\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 2500: 0.536712\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 92.1%\n",
      "Minibatch loss at step 3000: 0.489918\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.3%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.300000 ---- keep_prob_2: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.306956\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 27.7%\n",
      "Test accuracy: 30.4%\n",
      "Minibatch loss at step 500: 0.425345\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.2%\n",
      "Test accuracy: 91.0%\n",
      "Minibatch loss at step 1000: 0.524861\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 84.9%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1500: 0.370717\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 2000: 0.428580\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 86.2%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 2500: 0.503021\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 3000: 0.516686\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 92.6%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.300000 ---- keep_prob_2: 0.600000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.301484\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 26.7%\n",
      "Test accuracy: 29.5%\n",
      "Minibatch loss at step 500: 0.436436\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.0%\n",
      "Test accuracy: 90.8%\n",
      "Minibatch loss at step 1000: 0.572845\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1500: 0.398544\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 2000: 0.363430\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 93.1%\n",
      "Minibatch loss at step 2500: 0.424378\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 3000: 0.473221\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 93.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.300000 ---- keep_prob_2: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.309660\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 21.8%\n",
      "Test accuracy: 23.0%\n",
      "Minibatch loss at step 500: 0.438078\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.6%\n",
      "Test accuracy: 91.3%\n",
      "Minibatch loss at step 1000: 0.591365\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1500: 0.376220\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 2000: 0.384728\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 93.0%\n",
      "Minibatch loss at step 2500: 0.441625\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 93.0%\n",
      "Minibatch loss at step 3000: 0.538459\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.6%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.400000 ---- keep_prob_2: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302361\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 26.0%\n",
      "Test accuracy: 27.7%\n",
      "Minibatch loss at step 500: 0.376824\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.6%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.549820\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 1500: 0.339193\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2000: 0.311582\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2500: 0.328342\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 3000: 0.380871\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.400000 ---- keep_prob_2: 0.300000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302405\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 31.1%\n",
      "Test accuracy: 33.6%\n",
      "Minibatch loss at step 500: 0.423732\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.0%\n",
      "Test accuracy: 91.0%\n",
      "Minibatch loss at step 1000: 0.543302\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1500: 0.374391\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.4%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 2000: 0.428294\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 2500: 0.490175\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 3000: 0.585947\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 93.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.400000 ---- keep_prob_2: 0.400000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.300798\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 29.1%\n",
      "Test accuracy: 31.5%\n",
      "Minibatch loss at step 500: 0.466761\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.2%\n",
      "Test accuracy: 90.8%\n",
      "Minibatch loss at step 1000: 0.525850\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1500: 0.377831\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 2000: 0.349200\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 2500: 0.495235\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 93.1%\n",
      "Minibatch loss at step 3000: 0.400799\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.3%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.400000 ---- keep_prob_2: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.303798\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 28.0%\n",
      "Test accuracy: 30.4%\n",
      "Minibatch loss at step 500: 0.393974\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.5%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.572173\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1500: 0.351883\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 2000: 0.383998\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2500: 0.438800\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.4%\n",
      "Minibatch loss at step 3000: 0.462192\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.7%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.400000 ---- keep_prob_2: 0.600000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.305330\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 22.2%\n",
      "Test accuracy: 23.7%\n",
      "Minibatch loss at step 500: 0.418750\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.4%\n",
      "Test accuracy: 91.0%\n",
      "Minibatch loss at step 1000: 0.497058\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 1500: 0.415109\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 2000: 0.340132\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.4%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 2500: 0.407618\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 3000: 0.394148\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.400000 ---- keep_prob_2: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.311179\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 23.8%\n",
      "Test accuracy: 25.6%\n",
      "Minibatch loss at step 500: 0.404915\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.7%\n",
      "Test accuracy: 91.3%\n",
      "Minibatch loss at step 1000: 0.539390\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1500: 0.304786\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 2000: 0.316593\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2500: 0.447398\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 3000: 0.429851\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.9%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.299692\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 29.9%\n",
      "Test accuracy: 32.8%\n",
      "Minibatch loss at step 500: 0.382231\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.0%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.508502\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 1500: 0.306787\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.3%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2000: 0.293385\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2500: 0.354161\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.3%\n",
      "Minibatch loss at step 3000: 0.350178\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.4%\n",
      "Test accuracy: 94.2%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.300000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.316245\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 24.3%\n",
      "Test accuracy: 26.0%\n",
      "Minibatch loss at step 500: 0.393601\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.6%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.543048\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1500: 0.421762\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 2000: 0.356433\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 2500: 0.410873\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 3000: 0.471209\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.9%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.400000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.318307\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 21.0%\n",
      "Test accuracy: 22.8%\n",
      "Minibatch loss at step 500: 0.459876\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.9%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.506593\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 1500: 0.365140\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 93.1%\n",
      "Minibatch loss at step 2000: 0.384981\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2500: 0.422370\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 3000: 0.466412\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.3%\n",
      "Test accuracy: 93.8%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307533\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 27.7%\n",
      "Test accuracy: 30.1%\n",
      "Minibatch loss at step 500: 0.375453\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 84.8%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.540217\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 1500: 0.313055\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 2000: 0.316140\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2500: 0.447453\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.4%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 3000: 0.457087\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.600000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.305768\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 30.1%\n",
      "Test accuracy: 32.3%\n",
      "Minibatch loss at step 500: 0.383036\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.8%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1000: 0.528850\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.7%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 1500: 0.310639\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 2000: 0.383705\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 2500: 0.381069\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 3000: 0.430799\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302504\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 32.7%\n",
      "Test accuracy: 35.2%\n",
      "Minibatch loss at step 500: 0.385088\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.6%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.530155\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 1500: 0.346937\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2000: 0.339490\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 2500: 0.393039\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 3000: 0.418039\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.600000 ---- keep_prob_2: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.296850\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 24.6%\n",
      "Test accuracy: 26.6%\n",
      "Minibatch loss at step 500: 0.386038\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.502917\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 1500: 0.324637\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 2000: 0.268546\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.345013\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.5%\n",
      "Test accuracy: 94.3%\n",
      "Minibatch loss at step 3000: 0.405728\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Test accuracy: 94.5%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.600000 ---- keep_prob_2: 0.300000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.300595\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 21.3%\n",
      "Test accuracy: 22.8%\n",
      "Minibatch loss at step 500: 0.398258\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.7%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1000: 0.610905\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 1500: 0.386745\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2000: 0.380037\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2500: 0.433070\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 3000: 0.408122\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.600000 ---- keep_prob_2: 0.400000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.311615\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 27.3%\n",
      "Test accuracy: 29.2%\n",
      "Minibatch loss at step 500: 0.375472\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.8%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.514217\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 1500: 0.340251\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 86.9%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2000: 0.318757\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 2500: 0.389655\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 3000: 0.467191\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.600000 ---- keep_prob_2: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302598\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 25.7%\n",
      "Test accuracy: 28.1%\n",
      "Minibatch loss at step 500: 0.409086\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.0%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.523167\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 1500: 0.297816\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.4%\n",
      "Test accuracy: 93.4%\n",
      "Minibatch loss at step 2000: 0.288496\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2500: 0.412747\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 3000: 0.436366\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.600000 ---- keep_prob_2: 0.600000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.316197\n",
      "Minibatch accuracy: 4.7%\n",
      "Validation accuracy: 21.5%\n",
      "Test accuracy: 23.5%\n",
      "Minibatch loss at step 500: 0.365394\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.518629\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 1500: 0.318043\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2000: 0.243504\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2500: 0.379720\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 3000: 0.405921\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.5%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.600000 ---- keep_prob_2: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.304832\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 30.7%\n",
      "Test accuracy: 33.2%\n",
      "Minibatch loss at step 500: 0.370786\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.0%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1000: 0.509135\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 1500: 0.307551\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2000: 0.324136\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2500: 0.351934\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 3000: 0.374302\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.4%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.304414\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 30.1%\n",
      "Test accuracy: 33.0%\n",
      "Minibatch loss at step 500: 0.355382\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.494770\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.5%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 1500: 0.274908\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2000: 0.268147\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.310763\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 3000: 0.385103\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.9%\n",
      "Test accuracy: 94.6%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.300000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.289691\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 25.9%\n",
      "Test accuracy: 27.2%\n",
      "Minibatch loss at step 500: 0.401749\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.9%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.573927\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 85.7%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 1500: 0.341869\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2000: 0.289847\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2500: 0.416330\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 3000: 0.373237\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.3%\n",
      "Test accuracy: 93.6%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.400000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.308874\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 20.6%\n",
      "Test accuracy: 22.3%\n",
      "Minibatch loss at step 500: 0.416551\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.8%\n",
      "Test accuracy: 91.4%\n",
      "Minibatch loss at step 1000: 0.493591\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.7%\n",
      "Minibatch loss at step 1500: 0.299259\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2000: 0.350245\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2500: 0.381930\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 3000: 0.414179\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.2%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.303874\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 32.9%\n",
      "Test accuracy: 36.3%\n",
      "Minibatch loss at step 500: 0.383785\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.515067\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 1500: 0.360063\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.3%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2000: 0.298996\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2500: 0.390031\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 3000: 0.402268\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.3%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.600000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.310734\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 28.5%\n",
      "Test accuracy: 31.0%\n",
      "Minibatch loss at step 500: 0.388055\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.8%\n",
      "Minibatch loss at step 1000: 0.488217\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 1500: 0.292481\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2000: 0.286522\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.3%\n",
      "Minibatch loss at step 2500: 0.360740\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.3%\n",
      "Minibatch loss at step 3000: 0.388230\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.4%\n",
      "Test accuracy: 94.3%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.306423\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 28.4%\n",
      "Test accuracy: 29.9%\n",
      "Minibatch loss at step 500: 0.386971\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1000: 0.455744\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 1500: 0.264193\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.287301\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.362576\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 3000: 0.360451\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "keep_probs = [0, 0.3,0.4, 0.5, 0.6,0.7]\n",
    "tuneGrid = pd.DataFrame.from_records([(kp1,kp2,0) for kp1 in keep_probs for kp2 in keep_probs],\n",
    "                          columns=['drop_1','drop_2','test_accuracy'])\n",
    "#tuneGrid.head()\n",
    "for i in range(0,tuneGrid.shape[0]):\n",
    "  drop_1 , drop_2 = tuneGrid.iloc[i,0] , tuneGrid.iloc[i,1]\n",
    "  print(\"\\n>>>>>>>>>> keep_prob_1: %f ---- keep_prob_2: %f\" % (drop_1 , drop_2))\n",
    "  graph = tf.Graph()\n",
    "  tuneGrid.iloc[i,2] = create_nn2_model_dropout_and_run(graph,\n",
    "                         train_dataset,\n",
    "                         train_labels,\n",
    "                         valid_dataset,\n",
    "                         valid_labels,\n",
    "                         test_dataset,\n",
    "                         test_labels,\n",
    "                         np.array([drop_1,drop_2]),\n",
    "                         num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drop_1</th>\n",
       "      <th>drop_2</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>94.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>94.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>94.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>94.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>94.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>94.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>94.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drop_1  drop_2  test_accuracy\n",
       "0      0.0     0.0          94.93\n",
       "3      0.0     0.5          94.87\n",
       "5      0.0     0.7          94.79\n",
       "30     0.7     0.0          94.64\n",
       "4      0.0     0.6          94.58\n",
       "24     0.6     0.0          94.53\n",
       "35     0.7     0.7          94.50\n",
       "1      0.0     0.3          94.47\n",
       "28     0.6     0.6          94.46\n",
       "29     0.6     0.7          94.44"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneGrid.sort_values(by=['test_accuracy'],ascending=[False]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We did not get an improvement in test accuracy by using dropout__ as the best accuracy occours for keep_prob=0 both for hidden layer 1 and hidden layer 2 that means no dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks models: 3 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_nn3_model_dropout_and_run(graph,\n",
    "                         train_dataset,\n",
    "                         train_labels,\n",
    "                         valid_dataset,\n",
    "                         valid_labels,\n",
    "                         test_dataset,\n",
    "                         test_labels,\n",
    "                         dropout_vect,\n",
    "                         num_steps,\n",
    "                         hidden_size = 1024, \n",
    "                         num_labels=10,batch_size = 128):\n",
    "    \n",
    "    assert dropout_vect.shape == (3,)\n",
    "    \n",
    "    uniMax = 1/math.sqrt(hidden_size)\n",
    "    \n",
    "    with graph.as_default():\n",
    "      # Input data. For the training data, we use a placeholder that will be fed\n",
    "      # at run time with a training minibatch.\n",
    "      tf_train_dataset = tf.placeholder(tf.float32,shape=(batch_size, image_size * image_size))\n",
    "      tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "        \n",
    "      tf_valid_dataset = tf.constant(valid_dataset)\n",
    "      tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "      # Hidden 1\n",
    "      weights_1 = tf.Variable(tf.random_uniform([image_size * image_size, hidden_size], minval=-uniMax, maxval=uniMax),\n",
    "                             name='weights_1')\n",
    "      biases_1 = tf.Variable(tf.random_uniform([hidden_size],minval=-uniMax, maxval=uniMax),name='biases_1')\n",
    "      hidden_1 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_1) + biases_1)\n",
    "      \n",
    "      if dropout_vect[0]>0: \n",
    "        dropped_1 = tf.nn.dropout(hidden_1, dropout_vect[0])\n",
    "      else:\n",
    "        dropped_1 = hidden_1\n",
    "    \n",
    "      # Hidden 2\n",
    "      weights_2 = tf.Variable(tf.random_uniform([hidden_size, hidden_size], minval=-uniMax, maxval=uniMax),name='weights_2')\n",
    "      biases_2 = tf.Variable(tf.random_uniform([hidden_size],minval=-uniMax, maxval=uniMax),name='biases_2')\n",
    "      hidden_2 = tf.nn.relu(tf.matmul(dropped_1, weights_2) + biases_2)\n",
    "    \n",
    "      if dropout_vect[1]>0: \n",
    "        dropped_2 = tf.nn.dropout(hidden_2, dropout_vect[1])\n",
    "      else:\n",
    "        dropped_2 = hidden_2\n",
    "    \n",
    "      # Hidden 3\n",
    "      weights_3 = tf.Variable(tf.random_uniform([hidden_size, hidden_size], minval=-uniMax, maxval=uniMax),name='weights_3')\n",
    "      biases_3 = tf.Variable(tf.random_uniform([hidden_size],minval=-uniMax, maxval=uniMax),name='biases_3')\n",
    "      hidden_3 = tf.nn.relu(tf.matmul(dropped_2, weights_3) + biases_3)\n",
    "    \n",
    "      if dropout_vect[2]>0: \n",
    "        dropped_3 = tf.nn.dropout(hidden_3, dropout_vect[2])\n",
    "      else:\n",
    "        dropped_3 = hidden_3\n",
    "        \n",
    "      # Softmax \n",
    "      weights_4 = tf.Variable(tf.random_uniform([hidden_size, num_labels],minval=-uniMax, maxval=uniMax), name='weights_4')\n",
    "      biases_4 = tf.Variable(tf.random_uniform([num_labels],minval=-uniMax, maxval=uniMax),name='biases_4')\n",
    "      logits = tf.matmul(dropped_3, weights_4) + biases_4\n",
    "\n",
    "      # \n",
    "      loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "\n",
    "      # Optimizer.\n",
    "      global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "      learning_rate = tf.train.exponential_decay(0.5, global_step, 100000, 0.96, staircase=True)\n",
    "      optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "      #optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "\n",
    "      # Predictions for the training, validation, and test data.\n",
    "      train_prediction = tf.nn.softmax(logits)\n",
    "    \n",
    "      valid_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_1) + biases_1), weights_2) + biases_2),\n",
    "                  weights_3) + biases_3), weights_3) + biases_3)\n",
    "      test_prediction = tf.nn.softmax(\n",
    "        tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_1) + biases_1), weights_2) + biases_2), \n",
    "                   weights_3) + biases_3), weights_3) + biases_3)\n",
    "\n",
    "    test_accuracy = 0\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        tf.global_variables_initializer().run()\n",
    "        print(\"Initialized\")\n",
    "        for step in range(num_steps):\n",
    "            offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "            \n",
    "            batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "            batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "           \n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            \n",
    "            if (step % 500 == 0):\n",
    "              print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "              print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "              print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "              valid_prediction.eval(), valid_labels))\n",
    "              test_accuracy = accuracy(test_prediction.eval(), test_labels)\n",
    "              print(\"Test accuracy: %.1f%%\" % test_accuracy)\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307701\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 37.3%\n",
      "Test accuracy: 40.4%\n",
      "Minibatch loss at step 500: 0.360584\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 1000: 0.469022\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.7%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 1500: 0.253226\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 2000: 0.240038\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.5%\n",
      "Test accuracy: 94.6%\n",
      "Minibatch loss at step 2500: 0.289389\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 89.2%\n",
      "Test accuracy: 95.1%\n",
      "Minibatch loss at step 3000: 0.322523\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.2%\n",
      "Test accuracy: 95.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.304984\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 29.4%\n",
      "Test accuracy: 31.6%\n",
      "Minibatch loss at step 500: 0.341077\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.7%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1000: 0.471969\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 1500: 0.251770\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 2000: 0.250893\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 88.8%\n",
      "Test accuracy: 94.9%\n",
      "Minibatch loss at step 2500: 0.297448\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.0%\n",
      "Test accuracy: 95.0%\n",
      "Minibatch loss at step 3000: 0.317588\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.3%\n",
      "Test accuracy: 95.2%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302516\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 32.4%\n",
      "Test accuracy: 34.7%\n",
      "Minibatch loss at step 500: 0.345148\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1000: 0.456426\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 1500: 0.255399\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 2000: 0.238993\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.8%\n",
      "Minibatch loss at step 2500: 0.292971\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.0%\n",
      "Test accuracy: 95.0%\n",
      "Minibatch loss at step 3000: 0.336966\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 89.2%\n",
      "Test accuracy: 95.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.295936\n",
      "Minibatch accuracy: 7.0%\n",
      "Validation accuracy: 28.4%\n",
      "Test accuracy: 30.8%\n",
      "Minibatch loss at step 500: 0.353784\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.1%\n",
      "Minibatch loss at step 1000: 0.445134\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 93.1%\n",
      "Minibatch loss at step 1500: 0.287672\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2000: 0.288302\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.297238\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 3000: 0.384665\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.7%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.301717\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 26.6%\n",
      "Test accuracy: 28.5%\n",
      "Minibatch loss at step 500: 0.380463\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.6%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.477643\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 1500: 0.272061\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2000: 0.297947\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.6%\n",
      "Minibatch loss at step 2500: 0.322675\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.4%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 3000: 0.355782\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.0%\n",
      "Test accuracy: 94.7%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.300598\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 24.0%\n",
      "Test accuracy: 26.1%\n",
      "Minibatch loss at step 500: 0.380110\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.4%\n",
      "Test accuracy: 91.9%\n",
      "Minibatch loss at step 1000: 0.483790\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.7%\n",
      "Test accuracy: 93.0%\n",
      "Minibatch loss at step 1500: 0.248392\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2000: 0.239834\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.4%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 2500: 0.302955\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 3000: 0.374534\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.8%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307483\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 27.8%\n",
      "Test accuracy: 29.6%\n",
      "Minibatch loss at step 500: 0.340085\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.8%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1000: 0.493526\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 1500: 0.282992\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2000: 0.245270\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.8%\n",
      "Minibatch loss at step 2500: 0.322314\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.8%\n",
      "Test accuracy: 94.7%\n",
      "Minibatch loss at step 3000: 0.338469\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 89.2%\n",
      "Test accuracy: 94.8%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302600\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 30.2%\n",
      "Test accuracy: 32.5%\n",
      "Minibatch loss at step 500: 0.349657\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.1%\n",
      "Minibatch loss at step 1000: 0.483011\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.8%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 1500: 0.249873\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2000: 0.245125\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.6%\n",
      "Minibatch loss at step 2500: 0.331831\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.9%\n",
      "Test accuracy: 94.8%\n",
      "Minibatch loss at step 3000: 0.353008\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.9%\n",
      "Test accuracy: 94.7%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.000000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.301033\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 22.5%\n",
      "Test accuracy: 23.9%\n",
      "Minibatch loss at step 500: 0.357615\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.498823\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.9%\n",
      "Test accuracy: 93.4%\n",
      "Minibatch loss at step 1500: 0.234258\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2000: 0.252327\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 2500: 0.338273\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.9%\n",
      "Minibatch loss at step 3000: 0.341963\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.1%\n",
      "Test accuracy: 95.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307396\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 29.2%\n",
      "Test accuracy: 31.4%\n",
      "Minibatch loss at step 500: 0.386062\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.504871\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.3%\n",
      "Minibatch loss at step 1500: 0.289783\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.3%\n",
      "Test accuracy: 93.4%\n",
      "Minibatch loss at step 2000: 0.271553\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2500: 0.340984\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 3000: 0.368865\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.2%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302458\n",
      "Minibatch accuracy: 8.6%\n",
      "Validation accuracy: 25.9%\n",
      "Test accuracy: 28.1%\n",
      "Minibatch loss at step 500: 0.376510\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 91.8%\n",
      "Minibatch loss at step 1000: 0.528742\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.4%\n",
      "Minibatch loss at step 1500: 0.301931\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2000: 0.309805\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 2500: 0.352233\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 3000: 0.378735\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.4%\n",
      "Test accuracy: 94.4%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.295499\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 27.2%\n",
      "Test accuracy: 29.9%\n",
      "Minibatch loss at step 500: 0.381968\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.0%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.497010\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 1500: 0.278064\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.269744\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 2500: 0.337200\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 3000: 0.401494\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.1%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.302359\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 31.8%\n",
      "Test accuracy: 34.0%\n",
      "Minibatch loss at step 500: 0.411358\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 84.8%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.566983\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1500: 0.350257\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.2%\n",
      "Minibatch loss at step 2000: 0.344485\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2500: 0.433242\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 3000: 0.434307\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.300098\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 27.7%\n",
      "Test accuracy: 30.0%\n",
      "Minibatch loss at step 500: 0.390960\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 84.7%\n",
      "Test accuracy: 91.3%\n",
      "Minibatch loss at step 1000: 0.512336\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 1500: 0.316626\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.0%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2000: 0.298494\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.3%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2500: 0.407798\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 3000: 0.410648\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.8%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.307862\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 23.8%\n",
      "Test accuracy: 25.2%\n",
      "Minibatch loss at step 500: 0.368996\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 84.9%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.505228\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.7%\n",
      "Minibatch loss at step 1500: 0.283785\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2000: 0.317570\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.6%\n",
      "Minibatch loss at step 2500: 0.413433\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 87.4%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 3000: 0.451078\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.305330\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 23.5%\n",
      "Test accuracy: 24.6%\n",
      "Minibatch loss at step 500: 0.414282\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.0%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.535639\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.9%\n",
      "Test accuracy: 92.2%\n",
      "Minibatch loss at step 1500: 0.301088\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.5%\n",
      "Minibatch loss at step 2000: 0.327726\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 2500: 0.393329\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 3000: 0.399720\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.300828\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 33.9%\n",
      "Test accuracy: 36.5%\n",
      "Minibatch loss at step 500: 0.418009\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.508641\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 85.7%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 1500: 0.316903\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.2%\n",
      "Test accuracy: 93.4%\n",
      "Minibatch loss at step 2000: 0.296127\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 2500: 0.386357\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.0%\n",
      "Minibatch loss at step 3000: 0.395590\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.3%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.500000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.296510\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 22.1%\n",
      "Test accuracy: 22.9%\n",
      "Minibatch loss at step 500: 0.380850\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.0%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.450976\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.7%\n",
      "Minibatch loss at step 1500: 0.296183\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.1%\n",
      "Test accuracy: 93.3%\n",
      "Minibatch loss at step 2000: 0.338359\n",
      "Minibatch accuracy: 93.0%\n",
      "Validation accuracy: 87.4%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2500: 0.354809\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 3000: 0.411384\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.0%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.297658\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 30.1%\n",
      "Test accuracy: 31.9%\n",
      "Minibatch loss at step 500: 0.357413\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.4%\n",
      "Test accuracy: 92.0%\n",
      "Minibatch loss at step 1000: 0.508993\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.7%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 1500: 0.259119\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2000: 0.283875\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.5%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 2500: 0.355792\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 3000: 0.342225\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 89.2%\n",
      "Test accuracy: 94.8%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.305208\n",
      "Minibatch accuracy: 5.5%\n",
      "Validation accuracy: 18.4%\n",
      "Test accuracy: 19.4%\n",
      "Minibatch loss at step 500: 0.351363\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 91.8%\n",
      "Minibatch loss at step 1000: 0.468211\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.7%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 1500: 0.269485\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 93.9%\n",
      "Minibatch loss at step 2000: 0.290606\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.4%\n",
      "Minibatch loss at step 2500: 0.327652\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.5%\n",
      "Test accuracy: 94.8%\n",
      "Minibatch loss at step 3000: 0.322242\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.5%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.000000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.305279\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 28.4%\n",
      "Test accuracy: 31.4%\n",
      "Minibatch loss at step 500: 0.355813\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 91.8%\n",
      "Minibatch loss at step 1000: 0.480295\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 1500: 0.271640\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.273186\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 2500: 0.358344\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.5%\n",
      "Test accuracy: 94.6%\n",
      "Minibatch loss at step 3000: 0.363185\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Test accuracy: 94.7%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.305288\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 27.8%\n",
      "Test accuracy: 29.9%\n",
      "Minibatch loss at step 500: 0.366503\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.1%\n",
      "Test accuracy: 91.6%\n",
      "Minibatch loss at step 1000: 0.530955\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.6%\n",
      "Minibatch loss at step 1500: 0.269701\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.297010\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 87.9%\n",
      "Test accuracy: 94.3%\n",
      "Minibatch loss at step 2500: 0.298240\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 3000: 0.374658\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.5%\n",
      "Test accuracy: 94.6%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.305176\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 30.7%\n",
      "Test accuracy: 32.4%\n",
      "Minibatch loss at step 500: 0.391806\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 91.7%\n",
      "Minibatch loss at step 1000: 0.490209\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.7%\n",
      "Minibatch loss at step 1500: 0.303743\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2000: 0.306243\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.1%\n",
      "Minibatch loss at step 2500: 0.335607\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 3000: 0.380845\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.4%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.500000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.320172\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 27.2%\n",
      "Test accuracy: 29.6%\n",
      "Minibatch loss at step 500: 0.380462\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.0%\n",
      "Test accuracy: 91.5%\n",
      "Minibatch loss at step 1000: 0.502880\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.6%\n",
      "Test accuracy: 92.9%\n",
      "Minibatch loss at step 1500: 0.281713\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 87.5%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.297843\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 2500: 0.376167\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.1%\n",
      "Test accuracy: 94.2%\n",
      "Minibatch loss at step 3000: 0.399874\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.7%\n",
      "Test accuracy: 94.4%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.000000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.298923\n",
      "Minibatch accuracy: 13.3%\n",
      "Validation accuracy: 28.2%\n",
      "Test accuracy: 30.1%\n",
      "Minibatch loss at step 500: 0.374988\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 85.2%\n",
      "Test accuracy: 91.8%\n",
      "Minibatch loss at step 1000: 0.464464\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 86.1%\n",
      "Test accuracy: 92.5%\n",
      "Minibatch loss at step 1500: 0.259919\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.8%\n",
      "Test accuracy: 93.8%\n",
      "Minibatch loss at step 2000: 0.306579\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 2500: 0.320197\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.2%\n",
      "Test accuracy: 94.3%\n",
      "Minibatch loss at step 3000: 0.369080\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.8%\n",
      "Test accuracy: 94.7%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.500000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.296652\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 30.7%\n",
      "Test accuracy: 33.1%\n",
      "Minibatch loss at step 500: 0.351461\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 91.8%\n",
      "Minibatch loss at step 1000: 0.500775\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.3%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 1500: 0.281437\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.6%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.284011\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 88.4%\n",
      "Test accuracy: 94.6%\n",
      "Minibatch loss at step 2500: 0.352328\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 3000: 0.400430\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.7%\n",
      "\n",
      ">>>>>>>>>> keep_prob_1: 0.700000 ---- keep_prob_2: 0.700000 ---- keep_prob_3: 0.700000\n",
      "Initialized\n",
      "Minibatch loss at step 0: 2.312369\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 27.9%\n",
      "Test accuracy: 30.4%\n",
      "Minibatch loss at step 500: 0.386162\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 85.3%\n",
      "Test accuracy: 91.9%\n",
      "Minibatch loss at step 1000: 0.529773\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 86.4%\n",
      "Test accuracy: 92.8%\n",
      "Minibatch loss at step 1500: 0.261001\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 87.7%\n",
      "Test accuracy: 93.7%\n",
      "Minibatch loss at step 2000: 0.260295\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 88.0%\n",
      "Test accuracy: 94.3%\n",
      "Minibatch loss at step 2500: 0.303135\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 88.4%\n",
      "Test accuracy: 94.5%\n",
      "Minibatch loss at step 3000: 0.364417\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.6%\n",
      "Test accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "keep_probs = [0, 0.5, 0.7]\n",
    "tuneGrid = pd.DataFrame.from_records([(kp1,kp2,kp3,0) for kp1 in keep_probs for kp2 in keep_probs for kp3 in keep_probs],\n",
    "                          columns=['drop_1','drop_2','drop_3','test_accuracy'])\n",
    "#tuneGrid.head()\n",
    "for i in range(0,tuneGrid.shape[0]):\n",
    "  drop_1 , drop_2 , drop_3 = tuneGrid.iloc[i,0] , tuneGrid.iloc[i,1] , tuneGrid.iloc[i,2]\n",
    "  print(\"\\n>>>>>>>>>> keep_prob_1: %f ---- keep_prob_2: %f ---- keep_prob_3: %f\" % (drop_1 , drop_2, drop_3))\n",
    "  graph = tf.Graph()\n",
    "  tuneGrid.iloc[i,3] = create_nn2_model_dropout_and_run(graph,\n",
    "                         train_dataset,\n",
    "                         train_labels,\n",
    "                         valid_dataset,\n",
    "                         valid_labels,\n",
    "                         test_dataset,\n",
    "                         test_labels,\n",
    "                         np.array([drop_1,drop_2]),\n",
    "                         num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drop_1</th>\n",
       "      <th>drop_2</th>\n",
       "      <th>drop_3</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>95.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>95.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>95.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>94.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>94.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    drop_1  drop_2  drop_3  test_accuracy\n",
       "1      0.0     0.0     0.5          95.15\n",
       "0      0.0     0.0     0.0          95.11\n",
       "2      0.0     0.0     0.7          95.07\n",
       "8      0.0     0.7     0.7          95.02\n",
       "6      0.0     0.7     0.0          94.84\n",
       "5      0.0     0.5     0.7          94.83\n",
       "18     0.7     0.0     0.0          94.82\n",
       "24     0.7     0.7     0.0          94.74\n",
       "3      0.0     0.5     0.0          94.73\n",
       "7      0.0     0.7     0.5          94.72"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuneGrid.sort_values(by=['test_accuracy'],ascending=[False]).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We did not get an improvement in test accuracy by using dropout__ as although the best accuracy occours for keep_prob = 0 for hidden layers 1 and 2 and keep_prob = 0.5 for layers 3 the difference with the second best combination that is the no dropout option for all hidden layers is very tiny. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions \n",
    "\n",
    "* __Neural Networks models: 1 hidden layer__: __dropout not effective__\n",
    "  * We did not get an improvement in test accuracy by using dropout as the best accuracy occours for keep_prob=0 that means no dropout\n",
    "* __Neural Networks models: 2 hidden layers__: __dropout not effective__\n",
    "  * We did not get an improvement in test accuracy by using dropout as the best accuracy occours for keep_prob=0 both for hidden layer 1 and hidden layer 2 that means no dropout\n",
    "* __Neural Networks models: 3 hidden layers__: __dropout not effective__\n",
    "  * We did not get an improvement in test accuracy by using dropout as although the best accuracy occours for keep_prob = 0 for hidden layers 1 and 2 and keep_prob = 0.5 for layers 3 the difference with the second best combination that is the no dropout option for all hidden layers is very tiny.\n",
    "\n",
    "Also, __considering at most 3 hidden layers, the best model comes without L2 regularization and/or dropout with a test accuracy ~95.1%__"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
